# -*- coding: utf-8 -*-
"""agorahack2022-product-categories.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UR-BcC02AImrjF_xNiBGdfumheyeUvHk

Task solver
"""

import sys
import os
import re
import json
import loader

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

#!pip install tensorflow==2.7.0
#!pip install keras-nightly==2.7.0.dev2021100607
#import keras
import numpy as np
#import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
#print(keras.__version__)
#print(tf.__version__)

# Подключаем Google Drive в каталог ./google-drive
"""
!apt-get install -y -qq software-properties-common python-software-properties module-init-tools
!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null
!apt-get update -qq 2>&1 > /dev/null
!apt-get -y install -qq google-drive-ocamlfuse fuse
from google.colab import auth
auth.authenticate_user()
from oauth2client.client import GoogleCredentials
creds = GoogleCredentials.get_application_default()
import getpass
!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL
vcode = getpass.getpass()
!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}
"""
"""
from google.colab import drive
drive.mount('./google-drive')

!mkdir ./google-drive/MyDrive
#!ls -alR ./google-drive/MyDrive
#!google-drive-ocamlfuse ./google-drive
!mkdir ./google-drive/MyDrive/colab-data/agora-hack-2022 >/dev/null 2>&1
!echo "Files (expected: *.json)"
!ls -al ./google-drive/MyDrive/colab-data/agora-hack-2022

!pwd
!cd ./google-drive/MyDrive/colab-data/agora-hack-2022
!echo "Files (expected: *.json)"
!ls -al ./google-drive/MyDrive/colab-data/agora-hack-2022
os.chdir("./google-drive/MyDrive/colab-data/agora-hack-2022")
"""

script_folder = os.path.dirname(os.path.realpath(__file__))
data_folder = os.path.join(script_folder, "data")

# Data wrappers

class CItem:
  pid = ""    # product_id
  rid = None  # reference_id
  name = ""
  props = []
  is_ref = False

  @staticmethod
  def create(obj):
    me = CItem()
    me.load(obj)
    return me

  def load(self, obj):
    self.pid    = obj['product_id'] if ('product_id' in obj) else obj['id']
    self.rid    = obj['reference_id'] if 'reference_id' in obj else None
    self.name   = obj['name'] if 'name' in obj else ""
    self.is_ref = (True if obj['is_reference'] else False) if 'reference_id' in obj else False
    self.props  = obj['props'] if 'props' in obj else []

  def save(self):
    obj = {}
    obj['id'] = self.pid
    obj['reference_id'] = self.rid
    obj['name'] = self.name
    obj['is_reference'] = self.is_ref
    obj['props'] = self.props
    return obj

  def save_ex(self):
    obj = self.save()
    if(hasattr(self, 'name_tokens')):
      obj['name_tokens'] = self.name_tokens
    if(hasattr(self, 'props_norm')):
      obj['props_norm'] = self.props_norm
    obj['tags'] = self.get_tags()
    return obj

  def get_tags(self):
    if(not hasattr(self, 'tags_cache')):
      tags = []
      if(hasattr(self, 'name_tokens')):
        tags.extend(list(self.name_tokens))
      if(hasattr(self, 'props_norm')):
        for k,vals in self.props_norm.items():
          tags.append(k)
          for v in vals:
            for vi in v.split(' '):
              tags.append("%s:%s" % (k,vi))
      tags = set(tags)
      self.tags_cache = tags
    return self.tags_cache

  def __repr__(self):
    return "%s%s (%s)" % (self.p_id, "[REF]" if self.is_ref else "", self.name)

def load_items_json_full(s):
  items = json.loads(s)
  items = list([CItem.create(o) for o in items])
  return items

def load_items_json_on_demand(s):
  items = json.loads(s)
  for item in items:
    yield CItem.create(item)

def load_items_on_demand(items):
  for item in items:
    yield CItem.create(item)

# Preparing data
import json
import os
with open(os.path.join(data_folder, "agora_hack_products.all.extended.json"), "rt", encoding="utf8") as f:
  json_s = json.load(f)

# Заполняем x_full_tags, y_full_refs
x_full_tags = []
y_full_refs = []

for item in json_s:
  rid = item['reference_id'] if ('reference_id' in item) else None
  pid = item['product_id'] if ('product_id' in item) else item["id"]
  is_ref = (True if item['is_reference'] else False) if 'reference_id' in item else False
  ref = pid if is_ref else rid
  tags = item['tags']
  x_full_tags.append(tags)
  y_full_refs.append(ref)

# Подготавливаем словари tags, refs
all_tags_list = set()
all_refs_list = set()

for tags in x_full_tags:
  for tag in tags:
    all_tags_list.add(tag)
all_tags_list = list(all_tags_list)
for ref in y_full_refs:
    all_refs_list.add(ref)
all_refs_list = list(all_refs_list)

# Меняем данные в x_full_tags, y_full_refs на индексы в all_tags_list, all_refs_list
for i in range(len(x_full_tags)):
  tags = [all_tags_list.index(v) for v in x_full_tags[i]]
  tags_cats = np.zeros(len(all_tags_list))
  for t in tags:
    tags_cats[t] = 1;
  x_full_tags[i] = tags_cats
x_full_tags = np.array(x_full_tags)
for i in range(len(y_full_refs)):
  refs_cats = np.zeros(len(all_refs_list))
  refs_cats[all_refs_list.index(y_full_refs[i])] = 1
  y_full_refs[i] = refs_cats
y_full_refs = np.array(y_full_refs)

#print(len(x_full_tags), x_full_tags)
#print(len(y_full_refs), y_full_refs)
print("Nubmer of tags:\t%u" % len(all_tags_list))
print("Nubmer of refs:\t%u" % len(all_refs_list))

# Разбиваем данные на тренировочные и проверочные
n = x_full_tags.shape[0]
indices = np.random.permutation(x_full_tags.shape[0])
train_procent = 0.999
train_n = int(n * train_procent)
training_idx, test_idx = indices[:train_n], indices[train_n:]
x_train, x_test = x_full_tags[training_idx,:], x_full_tags[test_idx,:]
y_train, y_test = y_full_refs[training_idx,:], y_full_refs[test_idx,:]
print("Train: %u items; Test: %u items" % (x_train.shape[0], x_test.shape[0]))

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import numpy as np
#import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.optimizers import Adam
import math
import statistics
import random
import json

def save_model(file_base_name, model):
  with open(os.path.join(data_folder, "%s.model.json" % file_base_name), "wt") as f: print(model.to_json(), file=f, end="")
  with open(os.path.join(data_folder, "%s.classes.%s.json" % (file_base_name, 'tags')), "wt", encoding="utf8") as f: json.dump(all_tags_list, f, ensure_ascii=False, indent=4)
  with open(os.path.join(data_folder, "%s.classes.%s.json" % (file_base_name, 'refs')), "wt", encoding="utf8") as f: json.dump(all_refs_list, f, ensure_ascii=False, indent=4)
  model.save(os.path.join(data_folder, '%s.weights.h5' % file_base_name))

# Loading network and weights and testing it
def load_model(file_base_name):
  file_base_name = os.path.join(data_folder, file_base_name)
  with open(file_base_name + ".model.json", "rt") as f: model_json = f.read()
  model = tf.keras.models.model_from_json(model_json)
  model.load_weights(file_base_name + ".weights.h5")
  with open(file_base_name + ".classes.%s.json" % 'tags' , "rt", encoding="utf8") as f: all_tags_list_ = json.load(f)
  with open(file_base_name + ".classes.%s.json" % 'refs' , "rt", encoding="utf8") as f: all_refs_list_ = json.load(f)
  return model, all_tags_list_, all_refs_list_

#os.chdir("./google-drive/colab-data/nq2022-task4")
#print(keras.__version__)
#print(tf.__version__)
"""
json_file = open('model.json', 'r')
loaded_model_json = json.load(json_file)
json_file.close()
#loaded_model_json = loaded_model_json.replace("Functional", "Model")
print(loaded_model_json)
#loaded_model = tf.keras.models.model_from_json(loaded_model_json, custom_objects={'Functional':tf.keras.models.Model})
model = tf.keras.models.model_from_json(loaded_model_json)
#serialize_back = model.to_json()
#print(serialize_back)

# load weights into new model
#model.load_weights("weights.h5")
"""
input_len = x_train.shape[1]
output_len = y_train.shape[1]
model = keras.Sequential([
    Flatten(input_shape=(input_len, 1)),
    Dropout(0.2),
    Dense(800, activation='relu'),
    Dropout(0.2),
    Dense(output_len, activation='sigmoid')
])
print(model.summary())      # вывод структуры НС в консоль

loss='categorical_crossentropy'
optimizer=keras.optimizers.Adam(0.00001)
metrics=['accuracy']

if not('--continue' in sys.argv):
  model.compile(optimizer=optimizer, loss=loss, metrics = metrics)
else:
  # Load previous model and continue to train
  model_name = "agora"
  model, all_tags_list, all_refs_list = load_model(model_name) # "x.model.json", 'x.weights.h5'...
  model.compile(optimizer=optimizer, loss=loss, metrics = metrics)

# Само обучение
for i in range(100):
  try:
    history = model.fit(x_train, y_train, batch_size=16, epochs=10, validation_data=(x_test, y_test))
    #print(history.history)
    acc = history.history['accuracy']
    if(acc[-1] >= 0.999): break
    if(acc[0] > acc[-1]): print("Time to stop?")
  except KeyboardInterrupt:
    # User interrupt the program with ctrl+c
    break
print(model.summary())

if(True):
  # Saving model and weights
  model_name = "agora"
  save_model(model_name, model)


#if(True):  
#  model_name = "agora"
#  model, all_tags_list, all_refs_list = load_model(model_name) # "x.model.json", 'x.weights.h5'...

"""
i = 0
test_data = np.expand_dims(x_test[i], axis=0)
expected_data = np.argmax(y_test[i], axis=-1)
predicted = model.predict(test_data)
#star_names = ["Bad star 1", "Good star 2", "Good star 3"]
#print("Predicted:", predicted, ";Index:", np.argmax(predicted, axis=-1)[0], "; Name:", star_names[np.argmax(predicted, axis=-1)[0]])
predicted_idx = np.argmax(predicted, axis=-1)[0]
print("Predicted index:", predicted_idx, '; Propability:', predicted[0][predicted_idx], '; Expected:', expected_data)
"""